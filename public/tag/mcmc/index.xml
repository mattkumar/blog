<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mcmc | Matthew Kumar</title>
    <link>https://academic-demo.netlify.app/tag/mcmc/</link>
      <atom:link href="https://academic-demo.netlify.app/tag/mcmc/index.xml" rel="self" type="application/rss+xml" />
    <description>mcmc</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 31 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://academic-demo.netlify.app/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>mcmc</title>
      <link>https://academic-demo.netlify.app/tag/mcmc/</link>
    </image>
    
    <item>
      <title>Visualizing MCMC</title>
      <link>https://academic-demo.netlify.app/post/visualizing-mcmc/</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://academic-demo.netlify.app/post/visualizing-mcmc/</guid>
      <description>
&lt;script src=&#34;https://academic-demo.netlify.app/post/visualizing-mcmc/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://academic-demo.netlify.app/post/visualizing-mcmc/index_files/core-js/shim.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://academic-demo.netlify.app/post/visualizing-mcmc/index_files/react/react.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://academic-demo.netlify.app/post/visualizing-mcmc/index_files/react/react-dom.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://academic-demo.netlify.app/post/visualizing-mcmc/index_files/reactwidget/react-tools.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://academic-demo.netlify.app/post/visualizing-mcmc/index_files/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://academic-demo.netlify.app/post/visualizing-mcmc/index_files/reactable-binding/reactable.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;This article serves as an overview of a few interrelated statistical concepts I’ve been thinking about how to present to build intuition.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulating-data-from-a-known-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulating data from a known model&lt;/h1&gt;
&lt;p&gt;Simulate data from a logistic regression model with intercept = 2 and slope = 0.5&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set a seed
set.seed(123454321)

# true (known) parameters
a &amp;lt;- 2
b &amp;lt;- 0.5

# random data
x &amp;lt;- round(runif(5000, 1, 8))

# specify logistic model components
# linear predictor
xb &amp;lt;- a + b*x

# inverse logit - probability scale
p &amp;lt;- 1/(1 + exp(-xb))

# with probabilities, simulate the outcome
y &amp;lt;- rbinom(n = 5000, size = 1, prob = p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the simulated data, we can specify the model and see if we can recover the true values&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_model &amp;lt;- glm(y ~ x, family = binomial)

broom::tidy(my_model) %&amp;gt;%
  reactable::reactable()&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; class=&#34;reactable html-widget&#34; style=&#34;width:auto;height:auto;&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;tag&#34;:{&#34;name&#34;:&#34;Reactable&#34;,&#34;attribs&#34;:{&#34;data&#34;:{&#34;term&#34;:[&#34;(Intercept)&#34;,&#34;x&#34;],&#34;estimate&#34;:[1.8842352325007,0.473353164334316],&#34;std.error&#34;:[0.178699757620394,0.0537122925003526],&#34;statistic&#34;:[10.544139833157,8.81275295280328],&#34;p.value&#34;:[5.40653125250797e-26,1.22109449670334e-18]},&#34;columns&#34;:[{&#34;accessor&#34;:&#34;term&#34;,&#34;name&#34;:&#34;term&#34;,&#34;type&#34;:&#34;character&#34;},{&#34;accessor&#34;:&#34;estimate&#34;,&#34;name&#34;:&#34;estimate&#34;,&#34;type&#34;:&#34;numeric&#34;},{&#34;accessor&#34;:&#34;std.error&#34;,&#34;name&#34;:&#34;std.error&#34;,&#34;type&#34;:&#34;numeric&#34;},{&#34;accessor&#34;:&#34;statistic&#34;,&#34;name&#34;:&#34;statistic&#34;,&#34;type&#34;:&#34;numeric&#34;},{&#34;accessor&#34;:&#34;p.value&#34;,&#34;name&#34;:&#34;p.value&#34;,&#34;type&#34;:&#34;numeric&#34;}],&#34;defaultPageSize&#34;:10,&#34;paginationType&#34;:&#34;numbers&#34;,&#34;showPageInfo&#34;:true,&#34;minRows&#34;:1,&#34;dataKey&#34;:&#34;9f0967091c059053b4f177338da07c54&#34;},&#34;children&#34;:[]},&#34;class&#34;:&#34;reactR_markup&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;random-walk-metropolis-hastings&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Random Walk Metropolis-Hastings&lt;/h1&gt;
&lt;p&gt;In this next bit, we’ll build our own MCMC sampler for a Bayesian flavor of logistic regression.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# likelihood
likelihood &amp;lt;- function(intercept, slope){
  xb &amp;lt;- intercept + slope*x
  p &amp;lt;- 1/(1 + exp(-xb))
  sum(dbinom(y, size=1, prob=p, log=TRUE))
}

# priors 
prior &amp;lt;- function(intercept, slope){
  dnorm(intercept, sd = 1, log = T) + dnorm(slope, sd = 1, log = T)
}

# posterior
posterior &amp;lt;- function(intercept, slope){
  likelihood(intercept, slope) + prior(intercept, slope)
}

# candidate generation
candidate &amp;lt;- function(intercept, slope){
  intercept &amp;lt;- rnorm(1, mean = intercept, sd = 0.1) 
  slope &amp;lt;- rnorm(1, mean = slope, sd = 0.1)
  c(intercept, slope)
}

# Implement the Random Walk Metropolis-Hastings algorithm

# Setup:
# number of steps to run the analysis
n_steps &amp;lt;- 10000

# a place holder to collect results of the analysis  
mc &amp;lt;- matrix(ncol = 2, nrow = n_steps)
dc &amp;lt;- matrix(ncol = 1, nrow = n_steps)

# specify starting values
mc[1,] = c(0,0)
dc[1,] = &amp;quot;Init&amp;quot;


# Random Walk Metropolis-Hastings
for(i in 2:n_steps) {
  # draw a proposal candidate
  cand &amp;lt;- candidate(intercept = mc[i-1, 1], slope = mc[i-1, 2])
  
  # compute acceptance ratio
  ratio = exp(posterior(intercept = cand[1], slope = cand[2]) - posterior(intercept = mc[i-1, 1], slope = mc[i-1, 2]))
  
  # evaluate acceptance ratio
  if (runif(1) &amp;lt; ratio) {
    # if accept, keep proposal candidates, rinse + repeat 
    mc[i,] = c(cand[1], cand[2])
    dc[i,] = &amp;quot;Accept&amp;quot;
  } else {
    # if reject, use previous iterations points, rinse + repeat
    mc[i,] = c(mc[i-1,1], mc[i-1,2])
    dc[i,] = &amp;quot;Reject&amp;quot;
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below we’ll post process the resulting chain to obtain parameter estimates&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results &amp;lt;- mc %&amp;gt;% 
  as.data.frame() %&amp;gt;%
  select(Intercept = 1,
         Slope = 2) %&amp;gt;%
  cbind(dc %&amp;gt;% 
          as.data.frame() %&amp;gt;% 
          select(Decision = 1)) %&amp;gt;%
  mutate(z = row_number())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s compare what we obtained versus what we obtained by using the &lt;code&gt;glm()&lt;/code&gt; function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Our Results
cbind(mean(results$Intercept), mean(results$Slope))
##          [,1]      [,2]
## [1,] 1.818565 0.4924133

coefficients(glm(y ~ x, family = binomial))
## (Intercept)           x 
##   1.8842352   0.4733532&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
